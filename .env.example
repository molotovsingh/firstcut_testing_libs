# ===============================================================================
# Environment Variables for Parser-Extractor Matrix Testing
# ===============================================================================
# Copy this file to .env and add your actual API keys
#
# The system supports 8 event extraction providers (3 implemented, 5 planned):
#   Gateway APIs: LangExtract ✅, OpenRouter ✅, OpenCode Zen ✅
#   Direct APIs:  OpenAI ⏳, Anthropic ⏳, DeepSeek ⏳, Moonshot ⏳, Zhipu ⏳
#
# Select provider via Streamlit UI or set EVENT_EXTRACTOR environment variable
# ===============================================================================

# ====================
# Gateway API Providers (Multi-Model Aggregators) - IMPLEMENTED
# ====================

# LangExtract (Google Gemini) - Default Provider ✅
# Status: Implemented | Cost: Varies by Gemini pricing | Quality: 9/10
# Select via: EVENT_EXTRACTOR=langextract or Streamlit UI
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_API_KEY=your_google_api_key_here

# OpenRouter (Unified Multi-Provider API) ✅
# Status: Implemented | 11+ tested models | Quality: Up to 10/10
# Select via: EVENT_EXTRACTOR=openrouter or Streamlit UI
# OPENROUTER_API_KEY=your_openrouter_api_key_here
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# OPENROUTER_MODEL=openai/gpt-4o-mini
# OPENROUTER_TIMEOUT=60
#
# Tested OpenRouter Models (2025-10-01):
# All models below scored 10/10 for quality and reliability with response_format support
#
# Budget Champion:
#   deepseek/deepseek-r1-distill-llama-70b  ($0.03/M tokens, 10/10 quality)
#
# Balanced Options:
#   openai/gpt-4o-mini                      ($0.15/M tokens, 9/10 quality) ← RECOMMENDED
#   anthropic/claude-3-haiku                ($0.25/M tokens, 10/10 quality)
#   openai/gpt-3.5-turbo                    ($0.50/M tokens, 10/10 quality)
#
# Premium Options:
#   openai/gpt-4o                           ($3.00/M tokens, 10/10 quality)
#   anthropic/claude-3-5-sonnet             ($3.00/M tokens, 10/10 quality)
#   openai/gpt-4-turbo                      ($10.00/M tokens, 10/10 quality)
#
# Full test results: scripts/fallback_models_test.log
# Testing scripts: scripts/test_openrouter.py, scripts/test_fallback_models.py

# OpenCode Zen (Legal AI Gateway) ✅
# Status: Implemented | 2 tested models | Quality: 8/10
# Select via: EVENT_EXTRACTOR=opencode_zen or Streamlit UI
# OPENCODEZEN_API_KEY=your_opencode_zen_api_key_here
# OPENCODEZEN_BASE_URL=https://api.opencode-zen.com/v1
# OPENCODEZEN_MODEL=grok-code
# OPENCODEZEN_TIMEOUT=30
#
# Tested OpenCode Zen Models (2025-10-02):
# Budget Champion:
#   code-supernova                          (FREE, 8/10 quality) ← FREE TIER
#
# Balanced Options:
#   grok-code                               ($0.50/M tokens, 8/10 quality)
#
# Full test results: scripts/opencode_zen_models_test.log
# Testing scripts: scripts/test_opencode_zen.py, scripts/test_opencode_zen_models.py

# ====================
# Direct API Providers (Single-Vendor) - PLANNED (Phase 2.5)
# ====================

# OpenAI Direct API ⏳
# Status: Planned (Phase 2.5) | Models: GPT-4o, GPT-4o-mini, GPT-3.5-turbo
# Select via: EVENT_EXTRACTOR=openai or Streamlit UI
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_TIMEOUT=60
#
# Expected Models:
#   gpt-4o-mini                             ($0.15/M in, $0.60/M out, 9/10 expected)
#   gpt-4o                                  ($2.50/M in, $10.00/M out, 10/10 expected)
#   gpt-3.5-turbo                           ($0.50/M in, $1.50/M out, 10/10 expected)

# Anthropic Direct API ⏳
# Status: Planned (Phase 2.5) | Models: Claude 3.5 Sonnet, Opus, Haiku
# Select via: EVENT_EXTRACTOR=anthropic or Streamlit UI
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_BASE_URL=https://api.anthropic.com/v1
# ANTHROPIC_MODEL=claude-3-haiku-20240307
# ANTHROPIC_TIMEOUT=60
#
# Expected Models:
#   claude-3-haiku-20240307                 ($0.25/M in, $1.25/M out, 10/10 expected)
#   claude-3-5-sonnet-20241022              ($3.00/M in, $15.00/M out, 10/10 expected)
#   claude-3-opus-20240229                  ($15.00/M in, $75.00/M out, 10/10 expected)

# DeepSeek Direct API ⏳
# Status: Planned (Phase 2.5) | Models: DeepSeek R1, DeepSeek V3
# Select via: EVENT_EXTRACTOR=deepseek or Streamlit UI
# DEEPSEEK_API_KEY=your_deepseek_api_key_here
# DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
# DEEPSEEK_MODEL=deepseek-reasoner
# DEEPSEEK_TIMEOUT=60
#
# Expected Models:
#   deepseek-chat                           ($0.14/M in, $0.28/M out, 9/10 expected)
#   deepseek-reasoner                       (pricing TBD, 10/10 expected)

# Moonshot AI (Kimi K2) ⏳
# Status: Planned (Phase 2.5) | Models: Kimi K2 (1T params, 256K context)
# Select via: EVENT_EXTRACTOR=moonshot or Streamlit UI
# MOONSHOT_API_KEY=your_moonshot_api_key_here
# MOONSHOT_BASE_URL=https://api.moonshot.cn/v1
# MOONSHOT_MODEL=moonshot-v1-128k
# MOONSHOT_TIMEOUT=60
#
# Expected Models:
#   moonshot-v1-128k                        ($0.84/M tokens, 9/10 expected)
#   moonshot-v1-32k                         ($0.24/M tokens, 9/10 expected)
#   moonshot-v1-8k                          ($0.084/M tokens, 8/10 expected)

# Zhipu AI (ChatGLM) ⏳
# Status: Planned (Phase 2.5) | Models: GLM-4, GLM-4.5 (200K context)
# Select via: EVENT_EXTRACTOR=zhipu or Streamlit UI
# ZHIPU_API_KEY=your_zhipu_api_key_here
# ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# ZHIPU_MODEL=glm-4
# ZHIPU_TIMEOUT=60
#
# Expected Models:
#   glm-4                                   ($0.50/M tokens, 9/10 expected)
#   glm-4-air                               ($0.05/M tokens, 8/10 expected)
#   glm-4-flash                             ($0.01/M tokens, 7/10 expected)

# ====================
# Other Configuration
# ====================

# File paths (adjust as needed)
INPUT_DIR=input
OUTPUT_DIR=output

# ====================
# Research Plan Reference
# ====================
# For full implementation details, see:
#   docs/plans/parser-extractor-matrix-research-plan.md
#
# Phase Status:
#   Phase 1: Config Externalization ⏳ (planned)
#   Phase 2: Parser Abstraction ⏳ (planned)
#   Phase 2.5: Direct API Providers ⏳ (planned - adds 5 providers above)
#   Phase 3: Benchmark Harness ⏳ (planned)
#   Phase 3.5: User Selection UI ⏳ (planned)
#   Phase 4: Baseline Testing ⏳ (planned)
#   Phase 5: Alternative Parsers ⏳ (future)
